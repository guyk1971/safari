{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Benchmark EDA\n",
    "the goal of the notebook is to explore the datasets used for synthetic benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gkoren/scratch/code/github/guyk1971/safari\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
    "from typing import Dict\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "root_path = os.path.abspath('.')\n",
    "print(root_path)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Associative recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_assoc_recall_4000_30_131072.pt',\n",
       " 'test_assoc_recall_4000_30_131072.pt',\n",
       " 'train_assoc_recall_4000_40_32768.pt',\n",
       " 'test_assoc_recall_4000_40_32768.pt',\n",
       " 'train_assoc_recall_4000_30_32768.pt',\n",
       " 'test_assoc_recall_4000_30_32768.pt',\n",
       " 'train_assoc_recall_4000_60_32768.pt',\n",
       " 'test_assoc_recall_4000_60_32768.pt',\n",
       " 'train_assoc_recall_4000_40_8192.pt',\n",
       " 'test_assoc_recall_4000_40_8192.pt',\n",
       " 'train_assoc_recall_4000_30_2048.pt',\n",
       " 'test_assoc_recall_4000_30_2048.pt',\n",
       " 'train_assoc_recall_4000_100_2048.pt',\n",
       " 'train_assoc_recall_4000_100_2048-nodot.pt',\n",
       " 'train_assoc_recall_4000_100_8192.pt',\n",
       " 'test_assoc_recall_4000_100_8192.pt',\n",
       " 'train_assoc_recall_4000_100_32768.pt',\n",
       " 'test_assoc_recall_4000_100_32768.pt',\n",
       " 'train_assoc_recall_4000_60_4096.pt',\n",
       " 'test_assoc_recall_4000_60_4096.pt',\n",
       " 'test_assoc_recall_4000_100_100-nodot.pt',\n",
       " 'train_assoc_recall_4000_100_100.pt',\n",
       " 'train_assoc_recall_4000_100_100-nodot.pt',\n",
       " 'test_assoc_recall_4000_100_100.pt',\n",
       " 'test_assoc_recall_4000_100_2048-nodot.pt',\n",
       " 'test_assoc_recall_4000_100_2048.pt']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_root_path=os.path.join(root_path,'datasets','assoc_recall')\n",
    "ds_files = [f for f in os.listdir(data_root_path) if f.endswith('.pt')]\n",
    "ds_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4000, 2, 102])\n",
      "torch.Size([500, 2, 102])\n"
     ]
    }
   ],
   "source": [
    "# load a dataset\n",
    "num_examples=4000\n",
    "vocab_size=100\n",
    "input_seq_len=100\n",
    "train_tensor = torch.load(os.path.join(data_root_path, \n",
    "    f\"train_assoc_recall_{num_examples}_{vocab_size}_{input_seq_len}.pt\"))\n",
    "test_tensor = torch.load(os.path.join(data_root_path, \n",
    "    f\"test_assoc_recall_{num_examples}_{vocab_size}_{input_seq_len}.pt\"))\n",
    "\n",
    "print(train_tensor.shape)\n",
    "print(test_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the portion of training set samples in which the query appeared in the prompt is 0.62625\n",
      "the portion of training set samples in which the query appeared in the prompt is 0.636\n"
     ]
    }
   ],
   "source": [
    "# we need to check if there is an example where the last element in the sample is appearing for the 1st time\n",
    "cond_trn=[t[0,-1] in t[0,:-1] for t in train_tensor]\n",
    "print(f'the portion of training set samples in which the query appeared in the prompt is {np.sum(cond_trn)/len(cond_trn)}')\n",
    "\n",
    "cond_tst=[t[0,-1] in t[0,:-1] for t in test_tensor]\n",
    "print(f'the portion of training set samples in which the query appeared in the prompt is {np.sum(cond_tst)/len(cond_tst)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
